<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Pose Detection in Video Stream</title>
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/opencv.js/4.5.3/opencv.js"></script>
<style>
  .video-container {
    position: relative;
    width: 100%;
    max-width: 640px; /* Adjust based on your needs */
  }
  #canvas {
    position: absolute;
    top: 0;
    left: 0;
  }
</style>
</head>
<body>

<div class="video-container">
  <video class="input-video" controls autoplay></video>
  <canvas id="canvas" width="640" height="480" style="border:2px solid black;"></canvas>
</div>

<script>
  let model;

  async function loadModel() {
    console.log("Loading model...");
    model = await ort.InferenceSession.create('yolov8n-pose.onnx');
    console.log("Model loaded");
  }

  async function detectPose(frame) {
    // Preprocess the frame to match the input size of the model
    const inputTensor = new ort.Tensor('float32', frame.data, [1, 3, frame.rows, frame.cols]);
    const feeds = { input: inputTensor };
    const results = await model.run(feeds);
    const outputData = results.output.data;

    // Postprocess and draw poses
    drawPoses(outputData);
  }

  function drawPoses(detections) {
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    // Example drawing logic, adjust based on your model's output
    detections.forEach(detection => {
      ctx.beginPath();
      ctx.arc(detection.x, detection.y, 5, 0, 2 * Math.PI);
      ctx.fillStyle = 'red';
      ctx.fill();
    });
  }

  function captureFrame(video) {
    const canvas = document.createElement('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    return imageData;
  }

  async function processVideo() {
    const video = document.querySelector('.input-video');
    video.src = 'http://192.168.210.218:8889/cam'; // Set your video source URL here
    video.addEventListener('loadeddata', async () => {
      video.play();
      while (true) {
        if (video.paused || video.ended) {
          break;
        }
        const frame = captureFrame(video);
        await detectPose(frame);
        await new Promise(r => setTimeout(r, 100)); // Wait for a bit before processing the next frame
      }
    });
  }

  window.onload = async () => {
    await loadModel();
    await processVideo();
  };
</script>

</body>
</html>